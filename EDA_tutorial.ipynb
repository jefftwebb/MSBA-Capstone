{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOg4wL632rjGxC++d454eGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jefftwebb/MSBA-Capstone/blob/main/EDA_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA with  SQL, Python and R in Google Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "XBqPsLAh1g-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Connect to BigQuery, format table display and load R extension.\n",
        "\n",
        "This interactive authentication requires that you have a google account."
      ],
      "metadata": {
        "id": "SvFjll-dIgbY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Aj9nAb4IURd"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Data Table makes it more convenient to navigate tables within the notebook."
      ],
      "metadata": {
        "id": "zKfKY0MLtOW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "avYmejO8q3yx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The rpy2 package allows us to write R code."
      ],
      "metadata": {
        "id": "349K6vuzsKrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext rpy2.ipython\n"
      ],
      "metadata": {
        "id": "NyVxMGtkRouf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Magic commands to write SQL and R code\n",
        "\n",
        "Google colab is a web hosted version of a jupityr notebook. Project jupityr started in 2014 with the goal of making  ipython notebooks language agnostic.  Hence jupityr, which stands for \"Julia,\" \"Python,\" and \"R.\" In google colab we can write code chunks in a variety of programming languages in addition to the native Python via the so-called \"magic commands.\""
      ],
      "metadata": {
        "id": "sRV0St9lSkcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First: what are magic commands? "
      ],
      "metadata": {
        "id": "PFoZiK0AH3SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%magic"
      ],
      "metadata": {
        "id": "sdmFGMPlGukJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which ones are available? (The R magics only appear after you have loaded the `rpy2` extension.)"
      ],
      "metadata": {
        "id": "l1NFw8j3KiAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%lsmagic"
      ],
      "metadata": {
        "id": "VV6qCarqHYLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that there are two levels of magic commands:\n",
        "\n",
        "- %% affects the entire cell; \n",
        "- % affects an individual line.\n",
        "\n",
        "In this tutorial we'll be using bigquery magics (to write SQL against tables in bigquery) and R magics (to write R code).\n",
        "\n",
        "For example, the following cell uses %%bigquery to query the google analytics public dataset, storing the result in a pandas dataframe (the default format in .ipynb) defined in the cell magic statement as \"df.\" **In the code chunks below you will need to replace \"project-id\" with your own GCP project ID.**\n",
        "\n",
        "Here for illustration we return 10 rows from the entire dataset for Aug 1, 2017."
      ],
      "metadata": {
        "id": "drYbB7bVHayQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project project-id df\n",
        "\n",
        "SELECT * FROM bigquery-public-data.google_analytics_sample.ga_sessions_20170801\n",
        "limit 10"
      ],
      "metadata": {
        "id": "xvMfRKYSLhnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "qbXDx4Io3Gdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "WFSPa9P95_7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "id": "RMQGuseA2v_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "g_ant7tnJ1wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The arrays from BigQuery have been brought into a pandas dataframe as what appear to be JSON columns. These include: totals, trafficSource, device, geoNetwork, and hits. The grain of the data is one row per visit; these latter columns record information within visits, and would need to be aggregated to the visit level to preserve the grain. We won't do that here.\n",
        "\n",
        "I prefer to do EDA in R, so my ultimate goal is to produce a rectangular dataset that can be read into R for data exploration. However R cannot import the JSON columns (which it interprets as python dicts). To prepare for EDA in R  we need to go back and revise the initial query to flatten the data."
      ],
      "metadata": {
        "id": "YzK2oE7I5kCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Flatten Data\n",
        "\n",
        "For reference, here is a detailed [data dictionary](https://support.google.com/analytics/answer/3437719?hl=en&ref_topic=3416089).\n",
        "\n",
        "You will most likely want to create different tables as you explore different ideas during EDA.\n",
        "\n",
        "The goal here is to create a table without nested data, featuring just one row per session. (This entails avoiding the `hits` and `product` tables, for now, since unnesting those will generate multiple rows per session--equivalent to a mutating join.) We will also bring in a month's worth of data. \n",
        "\n"
      ],
      "metadata": {
        "id": "dx7o3b--7xDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project project-id df \n",
        "\n",
        "SELECT fullVisitorId, visitId, date,  device.*, totals.*, channelGrouping\n",
        "FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
        "WHERE _TABLE_SUFFIX BETWEEN '20160801' AND '20160831'"
      ],
      "metadata": {
        "id": "mB4Rke3HXATc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "PuKJTkFhSfK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "i1mu2ckwTRY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Import Data into R"
      ],
      "metadata": {
        "id": "IbUcg-eBVY7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already loaded the rpy2 package so we can now use R magic commands to load the df dataset into R. (-i stands for \"input.\")"
      ],
      "metadata": {
        "id": "lkhbb3BNCY8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%R -i df # Note: %R runs an R line of code in a python code chunk"
      ],
      "metadata": {
        "id": "7TevMcoSXW0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the tidyverse as well as other any other packages you would like to use. Note that you will need to install packages first. \n",
        "\n"
      ],
      "metadata": {
        "id": "fSoBKmGbWJWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R # Note: %%R defines an R code chunk\n",
        "\n",
        "library(tidyverse)\n"
      ],
      "metadata": {
        "id": "XO-g5cM--6Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the data."
      ],
      "metadata": {
        "id": "GQhfAU7BWW2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%R str(df)"
      ],
      "metadata": {
        "id": "7fGIV0UNWav_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good!"
      ],
      "metadata": {
        "id": "yOvv3YjoC8I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. EDA\n",
        "\n",
        "EDA is an art and a science. There is no one right way to explore a dataset. Use your creativity and critical thinking to explore hypotheses, and to ask and answer questions, based on your knowledge of the business problem and business context.\n",
        "\n",
        "Assume for now that the target variable for this project will be `transactionRevenue` and that the objective will be either explanatory (what causes purchases?) or predictive (which customers will buy?).  In the latter case we might be interested in predicting future revenue to do targeted marketing.   \n",
        "\n",
        "To illustrate the exploratory process, let's start with a hypothesis:  higher purchase rates and higher revenue will be associated with more pageviews. The logic would be that customers looking for something -- indicated by higher pageviews-- are more likely to buy. And: the more page view the more motivated the customer probably is and the more likely to buy. Note that there are two targets implied by this hypothesis:\n",
        "\n",
        "1. Purchase: a binary indicator for whether revenue for a session was greater than 0.\n",
        "2. Revenue: the amount spent.\n",
        "\n",
        "In EDA there are always a large number of possible hypotheses and questions, which can feel overwhelming, like looking for a needle in a haystack.  The procedure is to strategically limit exploration by--in this case--thinking about possible drivers of purchasing. "
      ],
      "metadata": {
        "id": "lR2ugW6UIq-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA Example\n",
        "\n",
        "Tactics and techniques:\n",
        "- Investigate errors by looking at individual rows\n",
        "- Imputation of NAs\n",
        "- Log transformation for right-skewed and/or zero inflated distributions\n",
        "- Histograms\n",
        "- 5 number summary\n",
        "- Scatterplots\n",
        "- Smoothing\n",
        "- Binning\n",
        "- Boxplots\n",
        "- Interactions"
      ],
      "metadata": {
        "id": "OWy7DqYpAYcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grain of the data \n",
        "\n",
        "One preliminary issue is to make sure that the grain of the data is what we expect. One row per visit?"
      ],
      "metadata": {
        "id": "V08dxU3fB3YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df$visitId |> unique() |> length() # calculate number of unique visits using base pipe"
      ],
      "metadata": {
        "id": "RXwa62bwB9Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df |> nrow() # calculate number of rows"
      ],
      "metadata": {
        "id": "zNxAOkCDDCJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not the same.  Arrgh! Row-by-row exploration will be required to understand what is going on."
      ],
      "metadata": {
        "id": "4Cl6mhNhDUrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "which(duplicated(df$visitId))[1] # find the first duplicated row"
      ],
      "metadata": {
        "id": "Z7chapHfDYHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%R df[107, ] # use the index of the duplicated row to return the row"
      ],
      "metadata": {
        "id": "dkeFOYIvQZH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df |> filter(visitId == 1470499213) # filter the data by the visitId for the dup row"
      ],
      "metadata": {
        "id": "ZcfZ7s6NQmyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting!  `visitId` is not unique.  However, we can create a unique ID by combining it with `fullVisitorId` and `date` (since a single session seems to be recorded twice by Google Anaytics if it happens to span the change in date from 11:59 PM to 12:00 AM)."
      ],
      "metadata": {
        "id": "xYtp1Q6DQ31I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df <- df |> mutate(unique_id = paste0(fullVisitorId, visitId, date)) # create unique id"
      ],
      "metadata": {
        "id": "HYzz2MYBrl1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%R df$unique_id |> unique() |> length() # recalculate number of visits"
      ],
      "metadata": {
        "id": "XmfMa9BmR1cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there is one row per unique visit.  \n",
        "\n",
        "It is worth noting that we could choose to treat a session that occurs over two days not as two sessions, as we've done, but as one session that is arbitrarily split by the clock. This is a data modeling decision, and as such is neither right nor wrong. Keep it in mind though, since we may want to revise it. "
      ],
      "metadata": {
        "id": "mnK3vrjiSNOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of `transactionRevenue`"
      ],
      "metadata": {
        "id": "72wBvcwwffEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%R head(df$transactionRevenue, 200) # check top of data"
      ],
      "metadata": {
        "id": "MafsyHItfmVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, a session that did not result in a purchase is coded `NaN`.  That should be recoded as 0 and the amount of the purchase should be returned to a legible number by dividing by 10^6. While we're at it, let's copy this column and shorten the name."
      ],
      "metadata": {
        "id": "A2CQLZ63hobc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "df <- df |> \n",
        "mutate(rev = transactionRevenue,\n",
        "       rev = rev/10^6, # transform revenue\n",
        "       rev = replace_na(rev, 0)) # replace NaNs w 0"
      ],
      "metadata": {
        "id": "p7ZEI8v7h_B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%R head(df$rev, 200) # check result"
      ],
      "metadata": {
        "id": "SUqXxYOPjNND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, visualize the distribution."
      ],
      "metadata": {
        "id": "SEjxXybPb4ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Note that here and in other viz I am not saving an object but just printing\n",
        "\n",
        "ggplot(data = df, aes(x = rev)) +\n",
        "geom_histogram() +\n",
        "labs(title = \"Distribution of purchase amounts\") # should always include a title\n"
      ],
      "metadata": {
        "id": "cgpCB3Azlob2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero inflated.  Let's take a look at just the distribution of revenue > 0."
      ],
      "metadata": {
        "id": "GeLlJsVzcEA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df |>\n",
        "filter(rev > 0) |>\n",
        "ggplot(aes(rev)) +\n",
        "geom_histogram() +\n",
        "labs(title = \"Distribution of revenue > 0\") "
      ],
      "metadata": {
        "id": "yCWe7eymcWsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check 5 number summary of `rev.`"
      ],
      "metadata": {
        "id": "dFiCAvPExgrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df %>%\n",
        "filter(rev > 0) %>%\n",
        "select(rev) %>%\n",
        "summary\n"
      ],
      "metadata": {
        "id": "fES6TTw6ndu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long right tail. Log normal? Looks like it:"
      ],
      "metadata": {
        "id": "hsJ2UH5slcZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df |>\n",
        "filter(rev > 0) |> # filter rev to be non-zero:  log(0) is undefined\n",
        "ggplot(aes(log(rev))) + # do log transform w/in ggplot\n",
        "geom_histogram() +\n",
        "labs(title = \"Distribution of log revenue > 0\") "
      ],
      "metadata": {
        "id": "y2NgpVGHnzFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may need to log transform `transactionRevenue` for modeling later on, depending on the algorithm."
      ],
      "metadata": {
        "id": "VNLrOU0Hcqoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of pageviews\n",
        "\n",
        "There should be a minimum of 1, since the visit was recorded in Google Analytics."
      ],
      "metadata": {
        "id": "Ejmj16zPDsJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(df$pageviews)"
      ],
      "metadata": {
        "id": "wLQqoBFHuMUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Could look into what an NA might mean (if anything) for pageviews."
      ],
      "metadata": {
        "id": "Rco9AtMFumrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "ggplot(df, aes(pageviews)) +\n",
        "geom_histogram() +\n",
        "labs(title = \"Distribution of pageviews\")\n"
      ],
      "metadata": {
        "id": "-wopnDr9DyHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strongly right skewed with large outliers. At least 50% of the customers viewed just one or two pages."
      ],
      "metadata": {
        "id": "PXTXJvxYu0Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Are pageviews related to revenue? \n",
        "\n",
        "Specifically does the proportion of purchases and related revenue go up with `pageviews`?\n",
        "\n"
      ],
      "metadata": {
        "id": "VSvKI5npvfE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scatterplots and smoothing**"
      ],
      "metadata": {
        "id": "OaOKj7h-5Sha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "ggplot(df, aes(pageviews, rev)) +\n",
        "geom_point() +\n",
        "geom_smooth(se = F) + # Uses default LOESS smoothing, good for picking out non-linearity\n",
        "labs(title = \"rev ~ pageviews\")"
      ],
      "metadata": {
        "id": "BCSRd47hvgWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps there is a positive relationship, but it is hard to tell whether the regression line's upward trend is due to influential points. Let's try a log transformation to reduce the influence of the outliers.\n",
        "\n",
        "Because `rev` includes 0s we do a `log(x + 1)` transformation, which has a nice property: the former 0s are now 1s, that, after log transformation, are 0s again, since `log(1) = 0`."
      ],
      "metadata": {
        "id": "JR3SxjEPwJC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "ggplot(df, aes(log(pageviews), log(rev + 1))) +\n",
        "geom_point() +\n",
        "geom_smooth(se = F) +\n",
        "labs(title = \"log(rev) ~ log(pageviews)\")"
      ],
      "metadata": {
        "id": "ey3yOUa0wed6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same story but still hard to read with the majority of the overplotted points at `log(rev + 1)` = 0."
      ],
      "metadata": {
        "id": "McoyWS4Bx-hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "df |>\n",
        "filter(pageviews > 1, rev > 0) |>\n",
        "ggplot(aes(log(pageviews), log(rev))) +\n",
        "geom_point() +\n",
        "geom_smooth(se = F)+\n",
        "labs(title = \"filtered log(rev) ~ log(pageviews)\")"
      ],
      "metadata": {
        "id": "2KBEUwvDyC0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binning**\n",
        "\n",
        "Binning is generally very useful for visualization. \n",
        "\n",
        "Let's bin `pageviews` and then calculate purchase rate and median purchase amount for each bin.  \n",
        "\n",
        "Two dpyr functions are helpful to create bins:  `cut_interval()` and `cut_number()`.\n",
        "\n",
        "`cut_interval()` attempts to make the bin widths the same."
      ],
      "metadata": {
        "id": "kBg83_AMykb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "df |>\n",
        "filter(!is.na(pageviews)) |>\n",
        "mutate(pageview_bins = cut_interval(log(pageviews), 12)) |> # log pageviews to reduce bin width\n",
        "group_by(pageview_bins) |> # group by bins to produce summary stats for each bin\n",
        "summarize(n = n(),\n",
        "          purchase_rate = sum(rev > 0)/n, # calculates the proportion of purchases in each bin\n",
        "          median_purchase = median(rev[rev > 0])) # calculates the median rev for rev > 0 in bins"
      ],
      "metadata": {
        "id": "Q9Lkp-8qEWEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cut_number()` attempts to put the same number of observations in each bin. It does not work well in this instance because there are so many observations at `pageviews` equal to 1 and 2."
      ],
      "metadata": {
        "id": "B3z_biqkfkcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Boxplots**\n",
        "\n",
        "Here is a boxplot that shows the pattern from the above table. We could use a barplot to visualize the above summary table but a boxplot is more efficient."
      ],
      "metadata": {
        "id": "V9cFQh95t3kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "df |>\n",
        "filter(!is.na(pageviews)) |>\n",
        "mutate(pageview_bins = cut_interval(log(pageviews), 8)) |> # reduce bin number for visualization\n",
        "ggplot(aes(pageview_bins, log(rev + 1)))+\n",
        "geom_boxplot() +\n",
        "labs(title = \"log(rev) ~ binned pageviews\")"
      ],
      "metadata": {
        "id": "TfRZh2DWOsql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions beget questions\n",
        "\n",
        "Strong bivariate relationships should be checked for interactions with a logical third variable.  \n",
        "\n",
        "Does the relationship between `transactionRevenue` and `pageviews` vary by `channelGrouping`? "
      ],
      "metadata": {
        "id": "CemKkf4Kr095"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "df |>\n",
        "filter(!is.na(pageviews)) |>\n",
        "mutate(pageview_bins = cut_interval(log(pageviews), 8)) |>\n",
        "group_by(pageview_bins, channelGrouping) |> # Group by both factors\n",
        "summarize(n = n(),\n",
        "          purchase_rate = sum(rev > 0)/n, \n",
        "          median_purchase = median(rev[rev > 0])) |>\n",
        "          filter(purchase_rate > 0,   # filter for better legibility in visualization\n",
        "                 n > 50) |> # n > 50 is an arbitrary cutoff\n",
        "ggplot(aes(pageview_bins, purchase_rate, fill = channelGrouping))  +\n",
        "geom_col(position = \"dodge\") +\n",
        "labs(title = \"Purchase rate by pageviews and channels\")"
      ],
      "metadata": {
        "id": "6YBdgGdA3dky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}